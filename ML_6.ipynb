{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "af473fba-4477-4702-bb24-9042b5335882",
      "metadata": {
        "id": "af473fba-4477-4702-bb24-9042b5335882"
      },
      "source": [
        "# Reinforcement Learning\n",
        "\n",
        "## Implement Reinforcement Learning using an example of a maze environment that the agent needs to explore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ca79df-12d5-4724-be00-391691bbb3c2",
      "metadata": {
        "id": "47ca79df-12d5-4724-be00-391691bbb3c2",
        "outputId": "ee9dea97-4b15-4b9f-e83d-51de707906a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the maze environment\n",
        "class Maze:\n",
        "    def __init__(self, size, start, goal, walls):\n",
        "        self.size = size\n",
        "        self.start = start\n",
        "        self.goal = goal\n",
        "        self.walls = walls\n",
        "        self.state = start\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.start\n",
        "        return self.state\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return self.state == self.goal\n",
        "\n",
        "    def get_possible_actions(self):\n",
        "        actions = ['up', 'down', 'left', 'right']\n",
        "        x, y = self.state\n",
        "        if x == 0:\n",
        "            actions.remove('up')\n",
        "        if x == self.size[0] - 1:\n",
        "            actions.remove('down')\n",
        "        if y == 0:\n",
        "            actions.remove('left')\n",
        "        if y == self.size[1] - 1:\n",
        "            actions.remove('right')\n",
        "        return actions\n",
        "\n",
        "    def take_action(self, action):\n",
        "        x, y = self.state\n",
        "        if action == 'up':\n",
        "            new_state = (x - 1, y)\n",
        "        elif action == 'down':\n",
        "            new_state = (x + 1, y)\n",
        "        elif action == 'left':\n",
        "            new_state = (x, y - 1)\n",
        "        elif action == 'right':\n",
        "            new_state = (x, y + 1)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid action\")\n",
        "\n",
        "        if new_state in self.walls or not (0 <= new_state[0] < self.size[0] and 0 <= new_state[1] < self.size[1]):\n",
        "            new_state = self.state\n",
        "\n",
        "        self.state = new_state\n",
        "        reward = 1 if self.state == self.goal else -0.01\n",
        "        return new_state, reward\n",
        "\n",
        "    def render(self):\n",
        "        maze = np.zeros(self.size)\n",
        "        maze[self.goal] = 2\n",
        "        for wall in self.walls:\n",
        "            maze[wall] = -1\n",
        "        maze[self.state] = 1\n",
        "        plt.imshow(maze, cmap='cool', vmin=-1, vmax=2)\n",
        "        plt.show()\n",
        "\n",
        "# Q-learning algorithm\n",
        "class QLearning:\n",
        "    def __init__(self, maze, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
        "        self.maze = maze\n",
        "        # Fixed number of actions ('up', 'down', 'left', 'right')\n",
        "        self.q_table = np.zeros((*maze.size, 4))  # Fixed to 4 actions\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.actions = ['up', 'down', 'left', 'right']  # Fixed actions\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        possible_actions = self.maze.get_possible_actions()  # Get possible actions for the current state\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.choice(possible_actions)  # Choose a valid random action\n",
        "        else:\n",
        "            # Only select the action with the highest Q-value from possible actions\n",
        "            action_values = {action: self.q_table[state[0], state[1], self.actions.index(action)] for action in possible_actions}\n",
        "            return max(action_values, key=action_values.get)\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state):\n",
        "        action_idx = self.actions.index(action)\n",
        "        best_next_action = np.max(self.q_table[next_state[0], next_state[1]])\n",
        "        self.q_table[state[0], state[1], action_idx] += self.alpha * (reward + self.gamma * best_next_action - self.q_table[state[0], state[1], action_idx])\n",
        "\n",
        "    def train(self, episodes):\n",
        "        for _ in range(episodes):\n",
        "            state = self.maze.reset()\n",
        "            while not self.maze.is_terminal():\n",
        "                action = self.choose_action(state)\n",
        "                next_state, reward = self.maze.take_action(action)\n",
        "                self.update_q_table(state, action, reward, next_state)\n",
        "                state = next_state\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    size = (5, 5)\n",
        "    start = (0, 0)\n",
        "    goal = (4, 4)\n",
        "    walls = [(2, 2), (3, 2), (1, 3)]\n",
        "\n",
        "    maze = Maze(size, start, goal, walls)\n",
        "    q_learning = QLearning(maze, alpha=0.1, gamma=0.9, epsilon=0.1)\n",
        "    q_learning.train(1000)\n",
        "\n",
        "    # Visualization of the learned policy\n",
        "    policy = np.full(size, '', dtype=object)\n",
        "    for i in range(size[0]):\n",
        "        for j in range(size[1]):\n",
        "            state = (i, j)\n",
        "            if state == goal:\n",
        "                policy[i, j] = 'G'\n",
        "            elif state in walls:\n",
        "                policy[i, j] = 'W'\n",
        "            else:\n",
        "                action_idx = np.argmax(q_learning.q_table[i, j])\n",
        "                policy[i, j] = q_learning.actions[action_idx][0].upper()\n",
        "\n",
        "    plt.imshow(np.where(policy == 'W', -1, np.where(policy == 'G', 2, 0)), cmap='cool', vmin=-1, vmax=2)\n",
        "    plt.title('Learned Policy')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IOwU3qGvwNZs"
      },
      "id": "IOwU3qGvwNZs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "924cfdda-f1a9-4942-a696-4904435a251c",
      "metadata": {
        "id": "924cfdda-f1a9-4942-a696-4904435a251c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}